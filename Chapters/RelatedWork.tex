\chapter{Related Work}
In this section are discussed the related work on specification and analysis of requirements, allocation of software architecture, and formal analysis of behavioral models, designed in Simulink.

\section{Specification and Analysis of Embedded Systems Requirements}
Embedded system requirements are captured in different representations, e.g., textual, tabular, graphical, etc. The textual representation, which is the scope of the analysis, can be conveniently classified into two classes: i) controlled natural language (CNL), ii) template-based methods.  The syntax and semantics of the CNLs are similar to natural language except that the lexicon and the syntax are restricted for different reasons, of which improving comprehensibility of the text and formal representations to support rigour analysis of the text are prominent. The ReSA language is designed to improve comprehensibility of requirements specifications as well as to be computer-processable. There are many computer-processable CNL in literature \cite{Kuhn2014ALanguages}, e.g., Attempto Controlled English (ACE) \cite{attempto96}, Processable English (PENG) \cite{Schwitter2002EnglishLanguage}, etc. Similar to most computer-processable languages, ReSA has limited syntactic constructions, and allows knowledge-representations, in contrast though, our language is catered for embedded systems and therefore it uses concepts as well as semantic rules that are domain-specific to embedded systems. Similar to PENG, its implementation supports look-ahead in order to enable predictive and guided specification.

The template-based methods, in particular requirements boilerplate uses templates (or boilerplates) which are reusable, recurrent patterns to specify requirements, e.g., CESAR boilerplates \cite{Farfeleder2011DODT:Development}, RAT, etc. The main drawback of existing requirements boilerplates are: i) the templates are usually too limited therefore not expressive enough, ii) it is not easy to find the appropriate boilerplate during specification. In this regard, ReSA extends boilerplates with a meta-model that guides for plausible instantiation of boilerplates.


\section{Formal Analysis of Simulink Models}
Several research endeavors have tackled the problem of formally analyzing Simulink models in order to gain better insight into the design of Simulink model, and they mainly differ in the aspects (or coverage) of the Simulink language that has been targeted for analysis and the formalism applied. Besides to the scalability of the techniques, their robustness to formally analyze various types of Simulink models is also crucial especially for the proposed methods to be useful in industry. In this related work on formal analysis of Simulink models, existing formalism and their applicability in industry are discussed, and also compared to our solutions.

Simulink already supports formal analysis of Simulink models via its Simulink Design Verifier (SDV) product\footnote{https://se.mathworks.com/products/sldesignverifier.html}. Though, there is limited resource to investigate about the pros and cons of the product, the study by Nellen et al. \cite{Nellen2018FormalRecommendations} indicates some limitations on its capability such as inconclusiveness on the verification results, lack of support to verify timed properties. The latter pros is also mentioned by Florian et al. \cite{Leitner2008SimulinkStudy} in the comparison against SPIN. For brevity, other approaches are classified into three categories, approaches that use Simulink traces, contract/theorem and model-to-model transformation. 

The PlasmaLab proposed by Nikolaos et al. \cite{Kekatos2018ConstructingHybridization} transforms Simulink sample traces into statistical models, which are eventually analyzed by their statistical mode checker. Albeit the checker is assisted by an algorithm that determines sufficiency of the sample traces, it is unclear how it works. Unlike many approaches, PlasmaLab can analyze any Simulink models as long as the simulation results sample trances, which is the main advantage. Ferrante et al. \cite{Hocking2016ProvingModels} use contract-based theory in order to lift the block specification, and rely on a combination of SAT solvers and the NuSMV model checker for analysis. Hocking et al. \cite{Ferrante2012ParallelSystems} use the PVS specification language for writing the specification, and rely on the PVS theorem prover for analysis. A limitation of this strategy is that both steps still require much user interaction, so it is error-prone and requires certain understanding of the formal analysis engines, which is not common among embedded systems engineers.

The model-to-model transformation approach basically transforms the Simulink model into a formal model that can be checked via model checking, e.g., for reachability properties. Bernat et al. \cite{Meenakshi2006ToolChecker} proposed transformation Simulink models that consist only discrete blocks, which are subsequently checked via the DiViNE model checker. The research endeavors proposed transformation only StateFlow/Simulink into timed and hybrid automata. The discussed model-to-model approaches are limited in scalability due the use of exact model checking. In contrast, our approach uses statistical model checking, and thus scales better albeit is not exhaustive. However, by collecting sufficient sample traces and consequently acceptable confidence value in the statistical analysis, the later challenge can be tackled. Furthermore, our approach supports transformation of any discrete and continuous blocks, and also blocks that are custom and StateFlow. The latter capability is achieved since our transformation abstracts the internal implementation of the blocks.


\section{Software Allocation Optimization}
Different allocation schemes deliver different system performance and therefore efficient software allocation is crucial. Ernest Wozniak et al. \cite{Wozniak2013AnArchitectures} proposed a synthesis mechanism for an AUTOSAR software application that can executed over multiple nodes, with the objective fulfilling timing requirements. In contrast, we consider power consumption and reliability requirements besides timing. Similarly, Salah Saidi et al. \cite{Saidi2015AnArchitectures} proposed an ILP based approach for allocation of an AUTOSAR application on a multi-core framework in order to reduce the overhead of inter-process communication while we consider a multi-nodes platform. Ivan Svogor et al. \cite{vsvogor2014extended} proposed a generic approach of identifying resource constraints and a way of handling different measurement units with Analytic Hierarchy Process (AHP) in order to allocate a component-based software application on a heterogeneous platform. However, the resource constraints are trivialized, e.g., end-to-end delay calculations, which require timing specifications and activation patterns of tasks. As opposed to the previously mentioned related work, we considered a system model with a multi-rate software application, which basically impose complex timing analysis due to complex timed paths from the source to the sink of communication signals \cite{mubeen2013support}. On a different work, there are research focusing on power and energy consumption in real-time distributed systems which are employ dynamic voltage scaling ~\cite{bambagini2016energy} and task consolidation by minimizing computational nodes ~\cite{faragardi2013towards}~\cite{devadas2012interplay}.